{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata(filename): \n",
    "    #trainSet = []\n",
    "    #testSet = []\n",
    "    dataset=pd.read_csv(filename)\n",
    "    dataset.drop(columns=\"pred\")\n",
    "    #dataset.drop(columns=\"class\")\n",
    "    dataset.drop(columns=\"spectrometric_redshift\")\n",
    "\n",
    "    print(len(dataset))\n",
    "    return dataset\n",
    "    \n",
    "#     lines = csv.reader(open(file1 , 'r')) \n",
    "#     dataset = list(lines)\n",
    "#     for i in range(len(dataset)):\n",
    "#         for j in range(len(dataset[i])):\n",
    "#             dataset[i][j] = float(dataset[i][j])\n",
    "#         testSet.append ( dataset[i] )\n",
    "#     return trainSet , testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset , n_folds): \n",
    "    dataset_split = list()\n",
    "    dataset_copy = dataset.values.tolist()\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds): \n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = random.randrange(len(dataset_copy)) \n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold) \n",
    "\n",
    "    print(len(dataset_split))\n",
    "    #print(dataset_split)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 591\n",
      "296\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure object at 0x00ED2E70>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def upsampling():\n",
    "    df=pd.read_csv('catalog1/cat1.csv')\n",
    "    c0 = 0\n",
    "    c1 = 0\n",
    "    for i in df['pred']:\n",
    "        if(i==0):\n",
    "            c0+=1\n",
    "        else:\n",
    "            c1+=1\n",
    "\n",
    "\n",
    "    print(c0,c1)\n",
    "\n",
    "    resample_size = c1//2+1\n",
    "    print(resample_size)\n",
    "\n",
    "\n",
    "    # Shuffle the Dataset.\n",
    "    shuffled_df = df.sample(frac=1,random_state=4)\n",
    "    # print(len(shuffled_df))\n",
    "\n",
    "\n",
    "    quaser = shuffled_df.loc[shuffled_df['pred'] == 1]\n",
    "    star = shuffled_df.loc[shuffled_df['pred'] == 0].sample(n=resample_size,random_state=42, replace=True)\n",
    "\n",
    "    # Concatenate both dataframes again\n",
    "    normalized_df = pd.concat([star, quaser])\n",
    "\n",
    "    #plot the dataset after the undersampling\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.countplot('pred', data=normalized_df)\n",
    "    plt.title('Balanced Classes')\n",
    "    plt.show()\n",
    "    return normalized_df\n",
    "\n",
    "ndf=upsampling()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>galex_objid</th>\n",
       "      <th>sdss_objid</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>extinction_u</th>\n",
       "      <th>extinction_g</th>\n",
       "      <th>...</th>\n",
       "      <th>r-i</th>\n",
       "      <th>r-z</th>\n",
       "      <th>i-z</th>\n",
       "      <th>fuv-nuv</th>\n",
       "      <th>fuv-u</th>\n",
       "      <th>fuv-g</th>\n",
       "      <th>fuv-r</th>\n",
       "      <th>fuv-i</th>\n",
       "      <th>fuv-z</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>595</td>\n",
       "      <td>3.061500e+18</td>\n",
       "      <td>1.237668e+18</td>\n",
       "      <td>22.511520</td>\n",
       "      <td>21.195988</td>\n",
       "      <td>19.865002</td>\n",
       "      <td>18.973518</td>\n",
       "      <td>18.316504</td>\n",
       "      <td>0.107390</td>\n",
       "      <td>0.083677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891483</td>\n",
       "      <td>1.548498</td>\n",
       "      <td>0.657015</td>\n",
       "      <td>-1.170900</td>\n",
       "      <td>-0.977488</td>\n",
       "      <td>-2.293020</td>\n",
       "      <td>-3.624006</td>\n",
       "      <td>-4.515490</td>\n",
       "      <td>-5.172504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>264</td>\n",
       "      <td>6.378727e+18</td>\n",
       "      <td>1.237668e+18</td>\n",
       "      <td>20.221161</td>\n",
       "      <td>20.016415</td>\n",
       "      <td>20.369156</td>\n",
       "      <td>20.702093</td>\n",
       "      <td>20.916876</td>\n",
       "      <td>0.063656</td>\n",
       "      <td>0.049601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332937</td>\n",
       "      <td>-0.547720</td>\n",
       "      <td>-0.214783</td>\n",
       "      <td>0.392256</td>\n",
       "      <td>0.792728</td>\n",
       "      <td>0.587982</td>\n",
       "      <td>0.940723</td>\n",
       "      <td>1.273661</td>\n",
       "      <td>1.488443</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>6.374821e+18</td>\n",
       "      <td>1.237667e+18</td>\n",
       "      <td>19.805792</td>\n",
       "      <td>19.761148</td>\n",
       "      <td>20.141541</td>\n",
       "      <td>20.368341</td>\n",
       "      <td>20.823620</td>\n",
       "      <td>0.080151</td>\n",
       "      <td>0.062453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226801</td>\n",
       "      <td>-0.682079</td>\n",
       "      <td>-0.455278</td>\n",
       "      <td>-0.179464</td>\n",
       "      <td>0.359043</td>\n",
       "      <td>0.314400</td>\n",
       "      <td>0.694792</td>\n",
       "      <td>0.921593</td>\n",
       "      <td>1.376871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>390</td>\n",
       "      <td>6.378727e+18</td>\n",
       "      <td>1.237668e+18</td>\n",
       "      <td>20.531384</td>\n",
       "      <td>20.145739</td>\n",
       "      <td>20.355513</td>\n",
       "      <td>20.620770</td>\n",
       "      <td>20.867689</td>\n",
       "      <td>0.078877</td>\n",
       "      <td>0.061461</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265257</td>\n",
       "      <td>-0.512177</td>\n",
       "      <td>-0.246920</td>\n",
       "      <td>-0.240528</td>\n",
       "      <td>-0.306337</td>\n",
       "      <td>-0.691982</td>\n",
       "      <td>-0.482208</td>\n",
       "      <td>-0.216951</td>\n",
       "      <td>0.029968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>450</td>\n",
       "      <td>6.378551e+18</td>\n",
       "      <td>1.237668e+18</td>\n",
       "      <td>20.388424</td>\n",
       "      <td>19.976339</td>\n",
       "      <td>20.265482</td>\n",
       "      <td>20.491510</td>\n",
       "      <td>20.669323</td>\n",
       "      <td>0.072227</td>\n",
       "      <td>0.056279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226028</td>\n",
       "      <td>-0.403841</td>\n",
       "      <td>-0.177813</td>\n",
       "      <td>-0.551939</td>\n",
       "      <td>-0.164793</td>\n",
       "      <td>-0.576878</td>\n",
       "      <td>-0.287735</td>\n",
       "      <td>-0.061707</td>\n",
       "      <td>0.116106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   galex_objid    sdss_objid          u          g          r  \\\n",
       "595         595  3.061500e+18  1.237668e+18  22.511520  21.195988  19.865002   \n",
       "264         264  6.378727e+18  1.237668e+18  20.221161  20.016415  20.369156   \n",
       "129         129  6.374821e+18  1.237667e+18  19.805792  19.761148  20.141541   \n",
       "390         390  6.378727e+18  1.237668e+18  20.531384  20.145739  20.355513   \n",
       "450         450  6.378551e+18  1.237668e+18  20.388424  19.976339  20.265482   \n",
       "\n",
       "             i          z  extinction_u  extinction_g  ...        r-i  \\\n",
       "595  18.973518  18.316504      0.107390      0.083677  ...   0.891483   \n",
       "264  20.702093  20.916876      0.063656      0.049601  ...  -0.332937   \n",
       "129  20.368341  20.823620      0.080151      0.062453  ...  -0.226801   \n",
       "390  20.620770  20.867689      0.078877      0.061461  ...  -0.265257   \n",
       "450  20.491510  20.669323      0.072227      0.056279  ...  -0.226028   \n",
       "\n",
       "          r-z       i-z   fuv-nuv     fuv-u     fuv-g     fuv-r     fuv-i  \\\n",
       "595  1.548498  0.657015 -1.170900 -0.977488 -2.293020 -3.624006 -4.515490   \n",
       "264 -0.547720 -0.214783  0.392256  0.792728  0.587982  0.940723  1.273661   \n",
       "129 -0.682079 -0.455278 -0.179464  0.359043  0.314400  0.694792  0.921593   \n",
       "390 -0.512177 -0.246920 -0.240528 -0.306337 -0.691982 -0.482208 -0.216951   \n",
       "450 -0.403841 -0.177813 -0.551939 -0.164793 -0.576878 -0.287735 -0.061707   \n",
       "\n",
       "        fuv-z  pred  \n",
       "595 -5.172504     0  \n",
       "264  1.488443     0  \n",
       "129  1.376871     0  \n",
       "390  0.029968     0  \n",
       "450  0.116106     0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def entropy_func(c, n):\n",
    "    \"\"\"\n",
    "    The math formula\n",
    "    \"\"\"\n",
    "    return -(c*1.0/n)*math.log(c*1.0/n, 2)\n",
    "\n",
    "def entropy_cal(c1, c2):\n",
    "    \"\"\"\n",
    "    Returns entropy of a group of data\n",
    "    c1: count of one class\n",
    "    c2: count of another class\n",
    "    \"\"\"\n",
    "    if c1== 0 or c2 == 0:  # when there is only one class in the group, entropy is 0\n",
    "        return 0\n",
    "    return entropy_func(c1, c1+c2) + entropy_func(c2, c1+c2)\n",
    "\n",
    "# get the entropy of one big circle showing above\n",
    "def entropy_of_one_division(division): \n",
    "    \"\"\"\n",
    "    Returns entropy of a divided group of data\n",
    "    Data may have multiple classes\n",
    "    \"\"\"\n",
    "    s = 0\n",
    "    n = len(division)\n",
    "    classes = set(division)\n",
    "    for c in classes:   # for each class, get entropy\n",
    "        n_c = sum(division==c)\n",
    "        e = n_c*1.0/n * entropy_cal(sum(division==c), sum(division!=c)) # weighted avg\n",
    "        s += e\n",
    "    return s, n\n",
    "\n",
    "# The whole entropy of two big circles combined\n",
    "def get_entropy(y_predict, y_real):\n",
    "    \"\"\"\n",
    "    Returns entropy of a split\n",
    "    y_predict is the split decision, True/Fasle, and y_true can be multi class\n",
    "    \"\"\"\n",
    "    if len(y_predict) != len(y_real):\n",
    "        print('They have to be the same length')\n",
    "        return None\n",
    "    n = len(y_real)\n",
    "    s_true, n_true = entropy_of_one_division(y_real[y_predict]) # left hand side entropy\n",
    "    s_false, n_false = entropy_of_one_division(y_real[~y_predict]) # right hand side entropy\n",
    "    s = n_true*1.0/n * s_true + n_false*1.0/n * s_false # overall entropy, again weighted average\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(object):\n",
    "    def __init__(self, max_depth):\n",
    "        self.depth = 0\n",
    "        self.max_depth = max_depth\n",
    "    def find_best_split(self, col, y):\n",
    "        \"\"\"\n",
    "        col: the column we split on\n",
    "        y: target var\n",
    "        \"\"\"\n",
    "        \n",
    "        min_entropy = 10    \n",
    "        n = len(y)\n",
    "        for value in set(col):  # iterating through each value in the column\n",
    "            y_predict = col < value  # separate y into 2 groups\n",
    "            my_entropy = get_entropy(y_predict, y)  # get entropy of this split\n",
    "            if my_entropy <= min_entropy:  # check if it's the best one so far\n",
    "                min_entropy = my_entropy\n",
    "                cutoff = value\n",
    "        return min_entropy, cutoff\n",
    "\n",
    "    def find_best_split_of_all(self, x, y):\n",
    "        \"\"\"\n",
    "        Find the best split from all features\n",
    "        returns: the column to split on, the cutoff value, and the actual entropy\n",
    "        \"\"\"\n",
    "        col = None\n",
    "        min_entropy = 1\n",
    "        cutoff = None\n",
    "        for i, c in enumerate(x):  # iterating through each feature\n",
    "            entropy, cur_cutoff = self.find_best_split(x[c], y)  # find the best split of that feature\n",
    "            if entropy == 0:    # find the first perfect cutoff. Stop Iterating\n",
    "                return i, cur_cutoff, entropy\n",
    "            elif entropy <= min_entropy:  # check if it's best so far\n",
    "                min_entropy = entropy\n",
    "                col = i\n",
    "                cutoff = cur_cutoff\n",
    "        return col, cutoff, min_entropy\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, x, y, par_node={}, depth=0):\n",
    "        \"\"\"\n",
    "        x: Feature set\n",
    "        y: target variable\n",
    "        par_node: will be the tree generated for this x and y. \n",
    "        depth: the depth of the current layer\n",
    "        \"\"\"\n",
    "        if par_node is None:   # base case 1: tree stops at previous level\n",
    "            return None\n",
    "        elif len(y) == 0:   # base case 2: no data in this group\n",
    "            return None\n",
    "        elif self.all_same(y):   # base case 3: all y is the same in this group\n",
    "            return {'val':y[0]}\n",
    "        elif depth >= self.max_depth:   # base case 4: max depth reached \n",
    "            return None\n",
    "        else:   # Recursively generate trees! \n",
    "            # find one split given an information gain \n",
    "            col, cutoff, entropy = self.find_best_split_of_all(x, y)   \n",
    "            y_left = y[[x.iloc[:, col] < cutoff]  # left hand side data\n",
    "            y_right = y[x.iloc[:, col] >= cutoff]  # right hand side data\n",
    "            par_node = {'col': df.columns, 'index_col':col,\n",
    "                      'cutoff':cutoff,\n",
    "                    'val': np.round(np.mean(y))}  # save the information \n",
    "            # generate tree for the left hand side data\n",
    "            par_node['left'] = self.fit(x[x[:, col] < cutoff], y_left, {}, depth+1)   \n",
    "            # right hand side trees\n",
    "            par_node['right'] = self.fit(x[x[:, col] >= cutoff], y_right, {}, depth+1)  \n",
    "            self.depth += 1   # increase the depth since we call fit once\n",
    "            self.trees = par_node  \n",
    "            return par_node\n",
    "        \n",
    "    def all_same(self, items):\n",
    "            return all(x == items[0] for x in items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('project/dataset/catalog1/cat1.csv')\n",
    "#df.head()\n",
    "#df.columns\n",
    "df=df.drop(['Unnamed: 0', 'spectrometric_redshift','pred'],axis=1)\n",
    "#df.head()\n",
    "#df.head()\n",
    "target=df['class']\n",
    "target\n",
    "df=df.drop(['class'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-2c84afcbb77c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# import pprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# pprint(m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-0ce41a6b0714>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, par_node, depth)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;31m# find one split given an information gain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_best_split_of_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0my_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# left hand side data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0my_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# right hand side data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             par_node = {'col': df.columns, 'index_col':col,\n",
      "\u001b[1;32mD:\\Personal\\Users\\bhavna\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Personal\\Users\\bhavna\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2146\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Personal\\Users\\bhavna\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[1;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1839\u001b[0m         \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1840\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=7)\n",
    "m = clf.fit(df, target)\n",
    "\n",
    "# import pprint\n",
    "# pprint(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Using Gini Index:\n",
      "Predicted values:\n",
      "[1 0 1 ... 1 1 1]\n",
      "Confusion Matrix:  [[ 82  45]\n",
      " [ 23 944]]\n",
      "Accuracy :  93.78427787934186\n",
      "Report :               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.65      0.71       127\n",
      "          1       0.95      0.98      0.97       967\n",
      "\n",
      "avg / total       0.93      0.94      0.94      1094\n",
      "\n",
      "Results Using Entropy:\n",
      "Predicted values:\n",
      "[1 0 1 ... 1 1 1]\n",
      "Confusion Matrix:  [[ 79  48]\n",
      " [ 21 946]]\n",
      "Accuracy :  93.6928702010969\n",
      "Report :               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.62      0.70       127\n",
      "          1       0.95      0.98      0.96       967\n",
      "\n",
      "avg / total       0.93      0.94      0.93      1094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df_new=pd.read_csv('catalog2/cat2.csv')\n",
    "df_new=df_new.drop(['Unnamed: 0', 'spectrometric_redshift','pred'],axis=1)\n",
    "\n",
    "Y=df_new['class']\n",
    "X=df_new.drop(['class'],axis=1)\n",
    "  \n",
    "\n",
    "# Spliting the dataset into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(  \n",
    "X, Y, test_size = 0.3, random_state = 100) \n",
    "\n",
    "      \n",
    "# Function to perform training with giniIndex. \n",
    "def train_using_gini(X_train, X_test, y_train): \n",
    "  \n",
    "    # Creating the classifier object \n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,max_depth=3, min_samples_leaf=5) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_gini.fit(X_train, y_train) \n",
    "    return clf_gini \n",
    "      \n",
    "# Function to perform training with entropy. \n",
    "def tarin_using_entropy(X_train, X_test, y_train): \n",
    "  \n",
    "    # Decision tree with entropy \n",
    "    clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100,max_depth = 3, min_samples_leaf = 5) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_entropy.fit(X_train, y_train) \n",
    "    return clf_entropy \n",
    "  \n",
    "  \n",
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object): \n",
    "  \n",
    "    # Predicton on test with giniIndex \n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    print(\"Predicted values:\") \n",
    "    print(y_pred) \n",
    "    return y_pred \n",
    "      \n",
    "# Function to calculate accuracy \n",
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"Confusion Matrix: \", \n",
    "        confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"Accuracy : \", \n",
    "    accuracy_score(y_test,y_pred)*100) \n",
    "      \n",
    "    print(\"Report : \", \n",
    "    classification_report(y_test, y_pred)) \n",
    "  \n",
    "\n",
    "      \n",
    "    # Building Phase \n",
    "clf_gini = train_using_gini(X_train, X_test, y_train) \n",
    "clf_entropy = tarin_using_entropy(X_train, X_test, y_train) \n",
    "      \n",
    "    # Operational Phase \n",
    "print(\"Results Using Gini Index:\") \n",
    "      \n",
    "    # Prediction using gini \n",
    "y_pred_gini = prediction(X_test, clf_gini) \n",
    "cal_accuracy(y_test, y_pred_gini) \n",
    "      \n",
    "print(\"Results Using Entropy:\") \n",
    "    # Prediction using entropy \n",
    "y_pred_entropy = prediction(X_test, clf_entropy) \n",
    "cal_accuracy(y_test, y_pred_entropy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
